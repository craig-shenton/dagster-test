{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad86725d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Heuristic Output:\n",
      "# LLM Cluster Interpretation\n",
      "\n",
      "### Performance Benchmarking Analysis\n",
      "\n",
      "1. **Key Patterns in Runtime Across Clusters:**\n",
      "   - Cluster 0 and Cluster 3 have lower runtimes compared to Cluster 1 and Cluster 2.\n",
      "   - Cluster 0 has the lowest runtime, while Cluster 1 has the highest.\n",
      "\n",
      "2. **Impact of Input Features and Output Format on Performance:**\n",
      "   - **Null Rate:** Higher null rates tend to increase runtime due to additional processing required for handling missing values.\n",
      "   - **Cardinality:** Higher cardinality can lead to longer runtimes as it increases the complexity of operations.\n",
      "   - **Output Format:** The choice of output format can impact performance; for example, Parquet may be faster than CSV due to its columnar storage.\n",
      "\n",
      "3. **Transitions or Thresholds:**\n",
      "   - No specific thresholds were explicitly mentioned in the data provided.\n",
      "\n",
      "4. **Efficient and Inefficient Configurations:**\n",
      "   - Cluster 0 and Cluster 3 can be considered more efficient due to their lower runtimes.\n",
      "   - Cluster 1, with high null rate and cardinality, may be less efficient in terms of performance.\n",
      "\n",
      "5. **Performance Heuristics:**\n",
      "   - Minimize null values in the dataset to improve performance.\n",
      "   - Optimize cardinality to avoid performance degradation, especially for large datasets.\n",
      "   - Choose efficient output formats like Parquet for better performance.\n",
      "   - Consider the trade-offs between speed and resource consumption when selecting tools like Polars or Pandas.\n",
      "   - Conduct thorough benchmarking to identify the most performant configurations for specific workloads.\n",
      "\n",
      "By following these heuristics and considering the impact of input features and output formats, you can optimize the performance of data engineering benchmarks across different clusters.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load full clustered dataset\n",
    "df = pd.read_parquet(\"../data/clustered_benchmark_data.parquet\")\n",
    "\n",
    "# Load LLM interpretation\n",
    "with open(\"../data/llm_cluster_analysis.md\", \"r\") as f:\n",
    "    llm_output = f.read()\n",
    "\n",
    "print(\"LLM Heuristic Output:\")\n",
    "print(llm_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c95005e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>runtime_ms</th>\n",
       "      <th>null_rate</th>\n",
       "      <th>cardinality</th>\n",
       "      <th>output_format</th>\n",
       "      <th>engine</th>\n",
       "      <th>cluster</th>\n",
       "      <th>rows</th>\n",
       "      <th>columns</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>regime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>high_card_pandas</th>\n",
       "      <td>882.18</td>\n",
       "      <td>0.20</td>\n",
       "      <td>7486.88</td>\n",
       "      <td>csv</td>\n",
       "      <td>pandas</td>\n",
       "      <td>2</td>\n",
       "      <td>541205.16</td>\n",
       "      <td>35.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>null_heavy_json</th>\n",
       "      <td>1051.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>549.85</td>\n",
       "      <td>json</td>\n",
       "      <td>pandas</td>\n",
       "      <td>1</td>\n",
       "      <td>301504.32</td>\n",
       "      <td>30.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>small_dense_parquet</th>\n",
       "      <td>105.59</td>\n",
       "      <td>0.05</td>\n",
       "      <td>52.01</td>\n",
       "      <td>parquet</td>\n",
       "      <td>polars</td>\n",
       "      <td>0</td>\n",
       "      <td>2939.90</td>\n",
       "      <td>12.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wide_polars</th>\n",
       "      <td>353.89</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2914.03</td>\n",
       "      <td>parquet</td>\n",
       "      <td>polars</td>\n",
       "      <td>3</td>\n",
       "      <td>51583.79</td>\n",
       "      <td>90.04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     runtime_ms  null_rate  cardinality output_format  engine  \\\n",
       "regime                                                                          \n",
       "high_card_pandas         882.18       0.20      7486.88           csv  pandas   \n",
       "null_heavy_json         1051.75       0.75       549.85          json  pandas   \n",
       "small_dense_parquet      105.59       0.05        52.01       parquet  polars   \n",
       "wide_polars              353.89       0.30      2914.03       parquet  polars   \n",
       "\n",
       "                     cluster       rows  columns  \n",
       "regime                                            \n",
       "high_card_pandas           2  541205.16    35.07  \n",
       "null_heavy_json            1  301504.32    30.83  \n",
       "small_dense_parquet        0    2939.90    12.31  \n",
       "wide_polars                3   51583.79    90.04  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_by_regime = df.groupby(\"regime\").agg({\n",
    "    \"runtime_ms\": \"mean\",\n",
    "    \"null_rate\": \"mean\",\n",
    "    \"cardinality\": \"mean\",\n",
    "    \"output_format\": lambda x: x.mode()[0],\n",
    "    \"engine\": lambda x: x.mode()[0],\n",
    "    \"cluster\": lambda x: x.mode()[0],  # Most common cluster for the regime\n",
    "    \"rows\": \"mean\",\n",
    "    \"columns\": \"mean\"\n",
    "}).round(2)\n",
    "\n",
    "summary_by_regime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00d439b",
   "metadata": {},
   "source": [
    "# üìä Evaluation of LLM-Generated Performance Heuristics\n",
    "\n",
    "This section evaluates the correctness and usefulness of the LLM-generated heuristics based on actual benchmark results. The synthetic dataset was generated with four performance regimes, each assigned to a distinct cluster by HDBSCAN.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Ground Truth: Regime Summary\n",
    "\n",
    "| Regime               | Cluster | Runtime (ms) | Null Rate | Cardinality | Output Format | Engine  |\n",
    "|----------------------|---------|--------------|-----------|-------------|----------------|---------|\n",
    "| small_dense_parquet  | 0       | 106          | 0.05      | 52          | parquet        | polars  |\n",
    "| null_heavy_json      | 1       | 1052         | 0.75      | 550         | json           | pandas  |\n",
    "| high_card_pandas     | 2       | 882          | 0.20      | 7487        | csv            | pandas  |\n",
    "| wide_polars          | 3       | 354          | 0.30      | 2914        | parquet        | polars  |\n",
    "\n",
    "---\n",
    "\n",
    "## ü§ñ LLM Output Summary\n",
    "\n",
    "**Key Statements:**\n",
    "1. Cluster 0 has the lowest runtime; Cluster 1 the highest.\n",
    "2. High null rates increase runtime.\n",
    "3. Higher cardinality increases complexity.\n",
    "4. Parquet is faster than CSV.\n",
    "5. Clusters 0 and 3 are efficient; Cluster 1 is inefficient.\n",
    "6. Recommended heuristics:\n",
    "   - Minimise nulls\n",
    "   - Optimise cardinality\n",
    "   - Prefer Parquet for performance\n",
    "   - Choose tools based on workload\n",
    "   - Benchmark real configurations\n",
    "\n",
    "---\n",
    "\n",
    "## üß† Evaluation of Claims\n",
    "\n",
    "| LLM Statement                                            | Match? | Assessment |\n",
    "|----------------------------------------------------------|--------|------------|\n",
    "| Cluster 0 has lowest, Cluster 1 has highest runtime       | ‚úÖ     | Matches runtime data |\n",
    "| High null rate increases runtime                         | ‚úÖ     | Null-heavy cluster is slowest |\n",
    "| High cardinality increases runtime                       | üü°     | Partially true; not the main factor |\n",
    "| Parquet is faster than CSV                               | ‚úÖ     | Parquet clusters (0, 3) are faster |\n",
    "| Clusters 0 and 3 are efficient; Cluster 1 inefficient    | ‚úÖ     | Matches runtime and input features |\n",
    "\n",
    "---\n",
    "\n",
    "## üìù Heuristic Evaluation\n",
    "\n",
    "| Heuristic Rule                                            | Ground Truth Alignment |\n",
    "|-----------------------------------------------------------|-------------------------|\n",
    "| Minimise nulls to improve performance                     | ‚úÖ Strong support       |\n",
    "| Optimise cardinality to avoid degradation                 | üü° Partial              |\n",
    "| Prefer efficient output formats (e.g. Parquet)            | ‚úÖ Strong support       |\n",
    "| Choose tools (e.g. Polars) based on performance needs     | ‚úÖ Matches observed     |\n",
    "| Benchmark configurations empirically                      | ‚úÖ Good advice          |\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Conclusion\n",
    "\n",
    "The LLM provided high-quality interpretation of cluster-level benchmarking results:\n",
    "- It correctly identified the impact of nulls, file format, and general efficiency patterns.\n",
    "- It produced realistic heuristics that map closely to the synthetic regimes.\n",
    "- Its one weakness was a tendency to generalise the role of cardinality without detecting more complex interactions.\n",
    "\n",
    "This evaluation demonstrates that large language models can successfully generate **interpretable and actionable insights** from unsupervised benchmark clustering when combined with structured prompts and real-world validation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

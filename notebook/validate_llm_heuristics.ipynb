{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad86725d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Heuristic Output:\n",
      "# LLM Cluster Interpretation\n",
      "\n",
      "### Performance Benchmarking Analysis\n",
      "\n",
      "1. **Key Patterns in Runtime Across Clusters:**\n",
      "   - Cluster 0 and Cluster 3 have lower runtimes compared to Cluster 1 and Cluster 2.\n",
      "   - Cluster 0 has the lowest runtime, while Cluster 1 has the highest.\n",
      "\n",
      "2. **Impact of Input Features and Output Format on Performance:**\n",
      "   - **Null Rate:** Higher null rates tend to increase runtime due to additional processing required for handling missing values.\n",
      "   - **Cardinality:** Higher cardinality can lead to longer runtimes as it increases the complexity of operations.\n",
      "   - **Output Format:** The choice of output format can impact performance; for example, Parquet may be faster than CSV due to its columnar storage.\n",
      "\n",
      "3. **Transitions or Thresholds:**\n",
      "   - No specific thresholds were explicitly mentioned in the data provided.\n",
      "\n",
      "4. **Efficient and Inefficient Configurations:**\n",
      "   - Cluster 0 and Cluster 3 can be considered more efficient due to their lower runtimes.\n",
      "   - Cluster 1, with high null rate and cardinality, may be less efficient in terms of performance.\n",
      "\n",
      "5. **Performance Heuristics:**\n",
      "   - Minimize null values in the dataset to improve performance.\n",
      "   - Optimize cardinality to avoid performance degradation, especially for large datasets.\n",
      "   - Choose efficient output formats like Parquet for better performance.\n",
      "   - Consider the trade-offs between speed and resource consumption when selecting tools like Polars or Pandas.\n",
      "   - Conduct thorough benchmarking to identify the most performant configurations for specific workloads.\n",
      "\n",
      "By following these heuristics and considering the impact of input features and output formats, you can optimize the performance of data engineering benchmarks across different clusters.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load full clustered dataset\n",
    "df = pd.read_parquet(\"../data/clustered_benchmark_data.parquet\")\n",
    "\n",
    "# Load LLM interpretation\n",
    "with open(\"../data/llm_cluster_analysis.md\", \"r\") as f:\n",
    "    llm_output = f.read()\n",
    "\n",
    "print(\"LLM Heuristic Output:\")\n",
    "print(llm_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c95005e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>runtime_ms</th>\n",
       "      <th>null_rate</th>\n",
       "      <th>cardinality</th>\n",
       "      <th>output_format</th>\n",
       "      <th>engine</th>\n",
       "      <th>cluster</th>\n",
       "      <th>rows</th>\n",
       "      <th>columns</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>regime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>high_card_pandas</th>\n",
       "      <td>882.18</td>\n",
       "      <td>0.20</td>\n",
       "      <td>7486.88</td>\n",
       "      <td>csv</td>\n",
       "      <td>pandas</td>\n",
       "      <td>2</td>\n",
       "      <td>541205.16</td>\n",
       "      <td>35.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>null_heavy_json</th>\n",
       "      <td>1051.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>549.85</td>\n",
       "      <td>json</td>\n",
       "      <td>pandas</td>\n",
       "      <td>1</td>\n",
       "      <td>301504.32</td>\n",
       "      <td>30.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>small_dense_parquet</th>\n",
       "      <td>105.59</td>\n",
       "      <td>0.05</td>\n",
       "      <td>52.01</td>\n",
       "      <td>parquet</td>\n",
       "      <td>polars</td>\n",
       "      <td>0</td>\n",
       "      <td>2939.90</td>\n",
       "      <td>12.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wide_polars</th>\n",
       "      <td>353.89</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2914.03</td>\n",
       "      <td>parquet</td>\n",
       "      <td>polars</td>\n",
       "      <td>3</td>\n",
       "      <td>51583.79</td>\n",
       "      <td>90.04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     runtime_ms  null_rate  cardinality output_format  engine  \\\n",
       "regime                                                                          \n",
       "high_card_pandas         882.18       0.20      7486.88           csv  pandas   \n",
       "null_heavy_json         1051.75       0.75       549.85          json  pandas   \n",
       "small_dense_parquet      105.59       0.05        52.01       parquet  polars   \n",
       "wide_polars              353.89       0.30      2914.03       parquet  polars   \n",
       "\n",
       "                     cluster       rows  columns  \n",
       "regime                                            \n",
       "high_card_pandas           2  541205.16    35.07  \n",
       "null_heavy_json            1  301504.32    30.83  \n",
       "small_dense_parquet        0    2939.90    12.31  \n",
       "wide_polars                3   51583.79    90.04  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_by_regime = df.groupby(\"regime\").agg({\n",
    "    \"runtime_ms\": \"mean\",\n",
    "    \"null_rate\": \"mean\",\n",
    "    \"cardinality\": \"mean\",\n",
    "    \"output_format\": lambda x: x.mode()[0],\n",
    "    \"engine\": lambda x: x.mode()[0],\n",
    "    \"cluster\": lambda x: x.mode()[0],  # Most common cluster for the regime\n",
    "    \"rows\": \"mean\",\n",
    "    \"columns\": \"mean\"\n",
    "}).round(2)\n",
    "\n",
    "summary_by_regime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00d439b",
   "metadata": {},
   "source": [
    "‚úÖ Summary of Ground Truth (from summary_by_regime)\n",
    "\n",
    "Regime\tCluster\tRuntime\tNull Rate\tCardinality\tOutput Format\tEngine\n",
    "small_dense_parquet\t0\t106 ms\t0.05\t52\tparquet\tpolars\n",
    "null_heavy_json\t1\t1052 ms\t0.75\t550\tjson\tpandas\n",
    "high_card_pandas\t2\t882 ms\t0.20\t7487\tcsv\tpandas\n",
    "wide_polars\t3\t354 ms\t0.30\t2914\tparquet\tpolars\n",
    "\n",
    "‚∏ª\n",
    "\n",
    "üß† Evaluation of LLM Output\n",
    "\n",
    "üîπ Claim 1: ‚ÄúCluster 0 has lowest runtime; Cluster 1 has highest‚Äù\n",
    "\n",
    "‚úÖ Correct\n",
    "Matches the runtime_ms ordering exactly:\n",
    "\t‚Ä¢\tCluster 0 = small_dense_parquet = 106 ms\n",
    "\t‚Ä¢\tCluster 1 = null_heavy_json = 1052 ms\n",
    "\n",
    "‚Üí Strong evidence the LLM interpreted the summary accurately.\n",
    "\n",
    "‚∏ª\n",
    "\n",
    "üîπ Claim 2: ‚ÄúHigh null rate increases runtime‚Äù\n",
    "\n",
    "‚úÖ Correct\n",
    "The highest null rate (0.75) is in null_heavy_json with the slowest runtime.\n",
    "Lowest null rate (0.05) in small_dense_parquet corresponds to the fastest runtime.\n",
    "\n",
    "‚∏ª\n",
    "\n",
    "üîπ Claim 3: ‚ÄúHigher cardinality leads to longer runtimes‚Äù\n",
    "\n",
    "üü° Partially correct\n",
    "\t‚Ä¢\thigh_card_pandas (cardinality ‚âà 7500) is slow (882 ms)\n",
    "\t‚Ä¢\tnull_heavy_json (cardinality ‚âà 550) is even slower (1052 ms)\n",
    "\t‚Ä¢\twide_polars has cardinality ‚âà 2900 and is faster (354 ms)\n",
    "\n",
    "‚Üí This is true in some cases, but not consistently across regimes.\n",
    "The LLM oversimplifies a non-linear interaction.\n",
    "\n",
    "‚∏ª\n",
    "\n",
    "üîπ Claim 4: ‚ÄúParquet is faster than CSV‚Äù\n",
    "\n",
    "‚úÖ Correct in context\n",
    "\t‚Ä¢\tparquet (used by clusters 0 and 3) is associated with faster runtimes\n",
    "\t‚Ä¢\tcsv (in high_card_pandas) is slower\n",
    "This matches the regime design.\n",
    "\n",
    "‚∏ª\n",
    "\n",
    "üîπ Claim 5: ‚ÄúCluster 0 and 3 are efficient; Cluster 1 is inefficient‚Äù\n",
    "\n",
    "‚úÖ Correct\n",
    "\t‚Ä¢\tCluster 0 = small_dense_parquet (fastest)\n",
    "\t‚Ä¢\tCluster 3 = wide_polars (moderate runtime, high column count)\n",
    "\t‚Ä¢\tCluster 1 = null_heavy_json (highest nulls + slowest)\n",
    "\n",
    "‚∏ª\n",
    "\n",
    "üîπ Heuristic Summary:\n",
    "\n",
    "Heuristic\tGround Truth Match\tComments\n",
    "Minimise nulls to improve performance\t‚úÖ\tStrong signal in data\n",
    "Optimise cardinality\tüü°\tTrue for extremes, but interaction effects present\n",
    "Prefer Parquet for better performance\t‚úÖ\tClear in both cluster 0 and 3\n",
    "Consider Polars vs Pandas tradeoffs\t‚úÖ\tMatches regime design (Polars is faster)\n",
    "Benchmark real workloads\t‚úÖ\tAlways good advice\n",
    "\n",
    "\n",
    "‚∏ª\n",
    "\n",
    "üßæ Overall Evaluation\n",
    "\n",
    "Metric\tAssessment\n",
    "Accuracy\t‚úÖ High ‚Äî LLM correctly identifies performance patterns\n",
    "Specificity\tüü° Medium ‚Äî Cardinality relationship is generalised\n",
    "Heuristic Usefulness\t‚úÖ Useful rules for system tuning\n",
    "Alignment to Regimes\t‚úÖ Strong mapping between clusters and regimes\n",
    "Limitations\tDid not detect thresholds or subtle interactions\n",
    "\n",
    "\n",
    "‚∏ª\n",
    "\n",
    "üîö Conclusion\n",
    "\n",
    "The LLM performed very well in interpreting the summarised benchmark clusters:\n",
    "\t‚Ä¢\tIt correctly ranked clusters by efficiency.\n",
    "\t‚Ä¢\tIt identified the dominant impact of null rate and output format.\n",
    "\t‚Ä¢\tIts general advice aligns with realistic performance engineering concerns."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
